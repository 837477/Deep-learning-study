# -*- coding: utf-8 -*-
"""practice4-iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/blackdew/tensorflow1/blob/master/practice4-iris.ipynb

# 아이리스 품종 분류
- github csv url: https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/iris.csv
"""

# 라이브러리 사용
import tensorflow as tf
import pandas as pd

# 1.과거의 데이터를 준비합니다.
파일경로 = 'csv/iris.csv'
아이리스 = pd.read_csv(파일경로)
아이리스.head()

# 원핫인코딩
인코딩 = pd.get_dummies(아이리스)
인코딩.head()
'''
품종
setosa
virginica
versicolor
setosa
...(계속)

이러한 형태를 원 핫 인코딩을 하게 된다면,
setosa    virginica    versicolor
   1          0            0
   0          1            0
   0          0            1
   1          0            0
...(계속)

이러한 형태로 매핑이 된다.
모든 딥러닝의 종속변수는 반드시 숫자 형태로 이루어져야하기 때문에 이러한 전처리 과정이 필요하다.
'''

# 칼럼이름 출력
print(인코딩.columns)

# 독립변수, 종속변수
독립 = 인코딩[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]
종속 = 인코딩[['품종_setosa', '품종_versicolor', '품종_virginica']]
print(독립.shape, 종속.shape)

# 2. 모델의 구조를 만듭니다
X = tf.keras.layers.Input(shape=[4])
Y = tf.keras.layers.Dense(3, activation='softmax')(X)
model = tf.keras.models.Model(X, Y)
model.compile(loss='categorical_crossentropy',
              metrics='accuracy')
'''
softmax : 정답을 확률 표현으로 나타내기 위함
setosa    virginica    versicolor
   1          0            0 -> 이 꽃은 setosa일 확률이 100%.
  0.7        0.3           0 -> 이 꽃은 setosa일 확률이 70%.
  0.2        0.3          0.5 -> 이 꽃은 setosa일 확률이 20%.
   1          0            0
...(계속)

분류에 사용하는 loss 는 -> categorical_crossentropy
회귀에 사용하는 loss 는 -> mse
'''


# 3.데이터로 모델을 학습(FIT)합니다.
model.fit(독립, 종속, epochs=100)

# 모델을 이용합니다. 
# 맨 처음 데이터 5개
print(model.predict(독립[:5]))
print(종속[:5])
print("##########################")

# 맨 마지막 데이터 5개
print(model.predict(독립[-5:]))
print(종속[-5:])
print("##########################")

# weights & bias 출력
print(model.get_weights())

